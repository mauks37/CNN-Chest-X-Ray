# -*- coding: utf-8 -*-
"""training Xception fine-tuning RandAugm avg 4 classes all_data  part2345.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1GO7v1bvEdRGOhHXZmxo5d8PBJZOfwWcp
"""

import numpy as np
import matplotlib.pyplot as plt
from matplotlib.image import imread
import tensorflow as tf
import pandas as pd
import random
from keras.models import load_model

gpu_info = !nvidia-smi
gpu_info = '\n'.join(gpu_info)
if gpu_info.find('failed') >= 0:
  print('Select the Runtime > "Change runtime type" menu to enable a GPU accelerator, ')
  print('and then re-execute this cell.')
else:
  print(gpu_info)

"""Keras guide:

https://keras.io/guides/transfer_learning/
"""

from google.colab import drive
drive.mount('/content/drive')

data_dir = '/content/drive/My Drive/Colab Notebooks/Mestrado final/KFolds mix_data aumentado/trein 2-3-4-5/'
valid_dir = '/content/drive/My Drive/Colab Notebooks/Mestrado final/KFolds mix_data aumentado/1/'
test_dir = '/content/drive/My Drive/Colab Notebooks/Mestrado final/RXT teste mix_data/'

tf.io.gfile.listdir(data_dir)

image_shape = (229,229,3)
batch_size = 32

from tensorflow.keras.preprocessing.image import ImageDataGenerator

image_gen = ImageDataGenerator()

image_gen.flow_from_directory(data_dir)

"""# **Creating the model**"""

from tensorflow.keras.applications.xception import Xception
from tensorflow.keras.models import Model
from tensorflow.keras.layers import Flatten,Dense

i = tf.keras.layers.Input([None, None, 3], dtype = tf.uint8)
x = tf.cast(i, tf.float32)
x = tf.keras.applications.xception.preprocess_input(x)

xception = tf.keras.applications.Xception(input_tensor=x, input_shape = image_shape, include_top = False, weights="imagenet", pooling="avg")

# Freeze all the layers
for layer in xception.layers:
    layer.trainable = False

z = xception.output
predictions = Dense(4, activation='softmax')(z)
model = Model(inputs=xception.input, outputs=predictions)

model.summary()

model.compile(loss='categorical_crossentropy',
              optimizer='adam',
              metrics=['accuracy'])

from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau

early_stop = EarlyStopping(monitor='val_loss',patience=3,verbose=2)

model_checkpoint  = ModelCheckpoint(
    filepath='/content/drive/My Drive/Colab Notebooks/Mestrado final/Novos treinamentos/Arquiteturas mix aumentado/ola/model_checkpoint1',
    save_weights_only=True,
    monitor='val_accuracy',
    mode='max',
    save_freq='epoch',
    save_best_only=True,
    options=None,
    initial_value_threshold=None,
    verbose = 0
)

reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2,
                              patience=5, min_lr=0.001)

train_image_gen = image_gen.flow_from_directory(data_dir,
                                                target_size=(229,229),
                                                color_mode='rgb',
                                                batch_size=batch_size,
                                                class_mode='categorical')

validation_image_gen = image_gen.flow_from_directory(valid_dir,
                                                target_size=(229,229),
                                                color_mode='rgb',
                                                batch_size=batch_size,
                                                class_mode='categorical')

from sklearn.utils import shuffle
test_image_gen = image_gen.flow_from_directory(test_dir,
                                                     target_size=(229,229),
                                                     color_mode='rgb',
                                                     batch_size=batch_size,
                                                     class_mode='categorical',
                                                     shuffle=False
                                               )

train_image_gen.class_indices

"""# **Training the model**"""

model.fit(train_image_gen,epochs=200,validation_data=validation_image_gen,callbacks=[early_stop,model_checkpoint,reduce_lr])

losses = pd.DataFrame(model.history.history)

losses[['loss','val_loss']].plot()

"""# **Fine tunning**"""

model.load_weights('/content/drive/My Drive/Colab Notebooks/Mestrado final/Novos treinamentos/Arquiteturas mix aumentado/ola/model_checkpoint1')

# Unfreeze all the layers
for layer in model.layers:
    layer.trainable = True

model.compile(loss='categorical_crossentropy',
              optimizer=tf.optimizers.Adam(1e-5),
              metrics=['accuracy'])

train_image_gen.class_indices

model.fit(train_image_gen,epochs=10,validation_data=validation_image_gen,callbacks=[model_checkpoint])

losses = pd.DataFrame(model.history.history)

losses[['loss','val_loss']].plot()

model.load_weights('/content/drive/My Drive/Colab Notebooks/Mestrado final/Novos treinamentos/Arquiteturas mix aumentado/ola/model_checkpoint1')

model.save('/content/drive/My Drive/Colab Notebooks/Mestrado final/Novos treinamentos/Arquiteturas mix aumentado/Xception_fine-tuning_RandAugm_avg_4_classes_mix_data_part2345.h5')

model.evaluate(test_image_gen)

pred_probabilities = model.predict(test_image_gen)

def int_predict (pred_probabilities):
  predictions = np.zeros((pred_probabilities.shape[0],1),dtype=int)
  i = 0
  while i < pred_probabilities.shape[0]:
    predictions[i,:] = [np.argmax(pred_probabilities[i])]
    i = i + 1

  return predictions

predictions = int_predict(pred_probabilities)

from sklearn.metrics import classification_report, confusion_matrix

test_image_gen.class_indices

confusion_matrix(test_image_gen.classes,predictions)

print(classification_report(test_image_gen.classes,predictions))

from sklearn.metrics import roc_curve, auc
from sklearn.preprocessing import label_binarize
from itertools import cycle

y_score = pred_probabilities
num_classes = test_image_gen.num_classes

# Obtenha as etiquetas verdadeiras de todas as imagens no gerador
y_test = test_image_gen.classes
y_test = label_binarize(y_test, classes=range(num_classes))

# Calcule as métricas ROC e AUC para cada classe
fpr = dict()
tpr = dict()
roc_auc = dict()
for i in range(num_classes):
    fpr[i], tpr[i], _ = roc_curve(y_test[:, i], y_score[:, i])
    roc_auc[i] = auc(fpr[i], tpr[i])

# Plote a curva ROC para cada classe
colors = cycle(['aqua', 'darkorange', 'cornflowerblue', 'green'])
for i, color in zip(range(num_classes), colors):
    plt.plot(fpr[i], tpr[i], color=color, lw=2,
             label='ROC curve of class {0} (area = {1:0.2f})'
             ''.format(i, roc_auc[i]))

plt.plot([0, 1], [0, 1], 'k--', lw=2)
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Receiver operating characteristic for multi-class')
plt.legend(loc="lower right")
plt.show()

# Agora, vamos dar zoom em na parte superior esquerda do gráfico.
plt.figure()
for i, color in zip(range(num_classes), colors):
    plt.plot(fpr[i], tpr[i], color=color, lw=2,
             label='ROC curve of class {0} (area = {1:0.2f})'
             ''.format(i, roc_auc[i]))

plt.plot([0, 1], [0, 1], 'k--', lw=2)
plt.xlim([0.0, 0.2])  # Ajusta o limite do eixo X para focar no início do gráfico
plt.ylim([0.8, 1.05])  # Ajusta o limite do eixo Y para focar na parte superior do gráfico
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Zoom na parte superior da Receiver operating characteristic to multi-class')
plt.legend(loc="lower right")
plt.show()