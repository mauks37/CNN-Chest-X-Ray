# -*- coding: utf-8 -*-
"""training VGG19 fine-tuning avg 4 classes all_data novo part1235.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1FIokdmnPmotCTtpdZODznRlgpCv5jw-7
"""

import numpy as np
import matplotlib.pyplot as plt
from matplotlib.image import imread
import tensorflow as tf
import pandas as pd
import random
from keras.models import load_model

gpu_info = !nvidia-smi
gpu_info = '\n'.join(gpu_info)
if gpu_info.find('failed') >= 0:
  print('Select the Runtime > "Change runtime type" menu to enable a GPU accelerator, ')
  print('and then re-execute this cell.')
else:
  print(gpu_info)

"""Keras guide:

https://keras.io/guides/transfer_learning/
"""

from google.colab import drive
drive.mount('/content/drive')

data_dir = '/content/drive/My Drive/Colab Notebooks/Mestrado final/KFolds mix_data/trein 1-2-3-5/'
valid_dir = '/content/drive/My Drive/Colab Notebooks/Mestrado final/KFolds mix_data/4/'

tf.io.gfile.listdir(data_dir)

image_shape = (224,224,3)
batch_size = 32

from tensorflow.keras.preprocessing.image import ImageDataGenerator

image_gen = ImageDataGenerator()

image_gen.flow_from_directory(data_dir)

"""# **Creating the model**"""

from tensorflow.keras.applications.vgg19 import VGG19
from tensorflow.keras.models import Model
from tensorflow.keras.layers import Flatten,Dense

i = tf.keras.layers.Input([None, None, 3], dtype = tf.uint8)
x = tf.cast(i, tf.float32)
x = tf.keras.applications.vgg19.preprocess_input(x)

vgg19 = tf.keras.applications.VGG19(input_tensor=x, input_shape = image_shape, include_top = False, weights="imagenet", pooling="avg")

# Freeze all the layers
for layer in vgg19.layers:
    layer.trainable = False

z = vgg19.output
predictions = Dense(4, activation='softmax')(z)
model = Model(inputs=vgg19.input, outputs=predictions)

model.summary()

model.compile(loss='categorical_crossentropy',
              optimizer='adam',
              metrics=['accuracy'])

from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau

early_stop = EarlyStopping(monitor='val_loss',patience=3,verbose=2)

model_checkpoint  = ModelCheckpoint(
    filepath='/content/drive/My Drive/Colab Notebooks/Mestrado final/Novos treinamentos/KFolds mix/model_checkpoint4',
    save_weights_only=True,
    monitor='val_accuracy',
    mode='max',
    save_freq='epoch',
    save_best_only=True,
    options=None,
    initial_value_threshold=None,
    verbose = 0
)

reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2,
                              patience=5, min_lr=0.001)

train_image_gen = image_gen.flow_from_directory(data_dir,
                                                #target_size=image_shape[:2],
                                                color_mode='rgb',
                                                batch_size=batch_size,
                                                class_mode='categorical'
                                                )

validation_image_gen = image_gen.flow_from_directory(valid_dir,
                                                #target_size=image_shape[:2],
                                                color_mode='rgb',
                                                batch_size=batch_size,
                                                class_mode='categorical'
                                                )

train_image_gen.class_indices

"""# **Training the model**"""

model.fit(train_image_gen,epochs=200,validation_data=validation_image_gen,callbacks=[early_stop,model_checkpoint,reduce_lr])

losses = pd.DataFrame(model.history.history)

losses[['loss','val_loss']].plot()

"""# **Fine tunning**"""

model.load_weights('/content/drive/My Drive/Colab Notebooks/Mestrado final/Novos treinamentos/KFolds mix/model_checkpoint4')

# Unfreeze all the layers
for layer in model.layers:
    layer.trainable = True

model.compile(loss='categorical_crossentropy',
              optimizer=tf.optimizers.Adam(1e-5),
              metrics=['accuracy'])

train_image_gen.class_indices

model.fit(train_image_gen,epochs=10,validation_data=validation_image_gen,callbacks=[model_checkpoint])

losses = pd.DataFrame(model.history.history)

losses[['loss','val_loss']].plot()

model.load_weights('/content/drive/My Drive/Colab Notebooks/Mestrado final/Novos treinamentos/KFolds mix/model_checkpoint4')

model.save('/content/drive/My Drive/Colab Notebooks/Mestrado final/Novos treinamentos/VGG19_fine-tuning_avg_4_classes_mix_data_part1235.h5')